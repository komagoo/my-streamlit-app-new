import os
import sys
import streamlit as st
from dotenv import load_dotenv

# LangChain VectorStoreìš© Pinecone: ì´ë¦„ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ë³„ì¹­ ì‚¬ìš©
from langchain_community.vectorstores import Pinecone as LangchainPinecone

# pinecone ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ (v3.x)â€”í´ë˜ìŠ¤ ì§ì ‘ import
from pinecone import Pinecone

# ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import pandas as pd
import re
from collections import defaultdict, Counter
import plotly.express as px
import base64

from langchain.docstore.document import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# í™˜ê²½ë³€ìˆ˜ì™€ .env ë¡œë“œ
load_dotenv()

pinecone_api_key = os.getenv("PINECONE_API_KEY")
if not pinecone_api_key:
    st.error("âŒ PINECONE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# Pinecone ê°ì²´ ìƒì„± (v3 ë°©ì‹)
pc = Pinecone(api_key=pinecone_api_key)
index_name = "maintenance-index"
if index_name not in pc.list_indexes().names():
    pc.create_index(name=index_name, dimension=1536)
index = pc.Index(index_name)

# ë¡œê³  ì´ë¯¸ì§€ ì¸ì½”ë”©
def get_base64_of_bin_file(bin_file_path):
    with open(bin_file_path, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

logo_path = "Hero_logo(final).png"
logo_base64 = get_base64_of_bin_file(logo_path)

# Streamlit í™”ë©´ ì„¤ì •
st.set_page_config(page_title="ğŸš€mySUNI X SK í”„ë¡œì íŠ¸", layout="wide")
st.markdown(f"""
<div style="background-color:#ff4b4b; height:30px; width:100%;"></div>
<div style="display:flex; align-items:center; padding:20px 30px;">
    <img src="data:image/png;base64,{logo_base64}" alt="logo" style="height:100px; margin-right:30px;">
    <div>
        <h1 style="margin:0; font-size:2.5rem; color:#222;">HERO</h1>
        <p style="margin:0; font-size:1.1rem; color:#555;">Hynix Equipment Response Operator</p>
    </div>
</div>
""", unsafe_allow_html=True)

# ë¡œê·¸ì¸ ì„¸ì…˜
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "api_key" not in st.session_state:
    st.session_state.api_key = None

# ë¡œê·¸ì¸ ë‹¨ê³„
if not st.session_state.logged_in:
    st.subheader("ğŸ”‘ ë¡œê·¸ì¸")
    username = st.text_input("ì•„ì´ë””")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")

    valid_users = {
        "mySUNI250728!@": "mySUNI250728!@"
    }
    if st.button("ë¡œê·¸ì¸"):
        if username in valid_users and password == valid_users[username]:
            st.session_state.logged_in = True
            st.session_state.username = username
            st.session_state.api_key = st.secrets["OPENAI_API_KEY"]
            st.success(f"âœ… {username}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!")
            st.rerun()
        else:
            st.error("âŒ ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# OpenAI í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = (
    st.session_state.get("api_key")
    or os.getenv("OPENAI_API_KEY")
    or (st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else None)
)
if not api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# âœ… ë°ì´í„° ë¡œë“œ ë° ë²¡í„°DB ìƒì„±
# ì˜ˆì‹œ: CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œì™€ ì»¬ëŸ¼ëª…ì€ ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •)
df = pd.read_csv("maintenance_data.csv")  # ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
df_success = pd.read_csv("maintenance_success.csv")  # ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½

# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
documents = [
    Document(page_content=str(row["ì •ë¹„ë…¸íŠ¸"]), metadata=dict(row))
    for _, row in df.iterrows()
]

# í…ìŠ¤íŠ¸ ë¶„í•  ë° ì„ë² ë”© ìƒì„±
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs_split = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings(openai_api_key=api_key)

# LangChainìš© Pinecone VectorDB ìƒì„±
vectordb = LangchainPinecone.from_documents(
    docs_split, embeddings, index_name=index_name, pinecone_api_key=pinecone_api_key
)

# âœ… LLM + ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ QA ì²´ì¸ ìƒì„±
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(search_kwargs={'k': 20}),  # ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ top 20
    return_source_documents=True
)


# ----------------------
# 6. ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
menu = st.sidebar.radio(
    "ğŸ“‚ ë©”ë‰´ ì„ íƒ",
    ["ğŸ”¹ ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ", "ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ"]
)


# ì´í›„ ë°ì´í„° ì—…ë¡œë“œ, ë¶„ì„, ì±—ë´‡ ë“± ê¸°ì¡´ ì½”ë“œ ì´ì–´ì„œ...
# 7. ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ í˜ì´ì§€
# ----------------------
if menu == "ğŸ”¹ ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ":
    st.subheader("ğŸ¤– HERO ì±—ë´‡ â€“ ì •ë¹„ ë¬¸ì œ, ì œê°€ ë‹¤ ì•Œê³ ìˆì–´ìš”!")


    example_keywords = [
        "wafer not", "plasma ignition failure",
        "pumpdown ì‹œê°„ ì§€ì—°", "slot valve ë™ì‘ ë¶ˆëŸ‰",
        "RF auto match ë¶ˆëŸ‰"
    ]
 # ------------------ í•­ìƒ ë³´ì´ëŠ” ì´ˆë°˜ ì¸ì‚¬ë§ ------------------
    example_keywords = [
        "wafer not", "plasma ignition failure",
        "pumpdown ì‹œê°„ ì§€ì—°", "slot valve ë™ì‘ ë¶ˆëŸ‰",
        "RF auto match ë¶ˆëŸ‰"
    ]
    st.markdown(f"""
    <div style="display:flex; justify-content:flex-start; margin-bottom:10px;">
        <div style="font-size:30px; margin-right:8px;">ğŸ¤–</div>
        <div style="background-color:#F1F0F0; color:black; padding:10px 15px;
                    border-radius:15px; max-width:80%;">
            ì•ˆë…•í•˜ì„¸ìš”ğŸ‘‹<br>
            ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì´ìŠˆ í•´ê²° ë„ìš°ë¯¸ HEROì…ë‹ˆë‹¤!<br>
            ì •ë¹„ ì´ìŠˆë¥¼ ì…ë ¥í•˜ì‹œë©´, HEROê°€ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì•„ í•´ê²°ì±…ì„ ì œì•ˆí•´ë“œë ¤ìš”.<br><br>
            ğŸ’¡ {' | '.join(example_keywords)}
        </div>
    </div>
    """, unsafe_allow_html=True)


    # ------------------ ë‹µë³€ ìƒì„± ë¡œë”© ìŠ¤í”¼ë„ˆ ------------------
    query = st.text_input(
        "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="search_query",
        placeholder="ì˜ˆ: slot valve ë™ì‘ì´ ì•ˆë¼ã… ã… "
    )


    # âœ… ì…ë ¥ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
    if query.strip():
        with st.spinner("ğŸ”„ ìœ ì‚¬ ì •ë¹„ ì‚¬ë¡€ì™€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            # ì‚¬ìš©ì ë§í’ì„ 
            st.markdown(f"""
            <div style="display:flex; justify-content:flex-end; margin-bottom:10px;">
                <div style="background-color:#DCF8C6; color:black;
                            padding:10px 15px; border-radius:15px;
                            max-width:70%; text-align:right;">
                    {query}
                </div>
                <div style="font-size:30px; margin-left:8px;">ğŸ‘¤</div>
            </div>
            """, unsafe_allow_html=True)


            # ----------------------
            # 1) RAG ê²€ìƒ‰
            # ----------------------
            output = qa_chain({"query": query})
            docs = output['source_documents']


            recommended = []
            seen_pairs = set()


            for doc in docs:
                note = doc.page_content.strip()
                for _, row in df_success.iterrows():
                    if row["ì¡°ì¹˜"] in note:
                        key = (row["ì¡°ì¹˜"], note)
                        if key in seen_pairs:
                            continue
                        seen_pairs.add(key)


                        matched_row = df[df['ì •ë¹„ë…¸íŠ¸'].astype(str).str.strip() == note]
                        equip_id = matched_row['ì¥ë¹„ID'].iloc[0] if 'ì¥ë¹„ID' in df.columns and not matched_row.empty else 'N/A'
                        model = matched_row['ëª¨ë¸'].iloc[0] if 'ëª¨ë¸' in df.columns and not matched_row.empty else 'N/A'
                        maint_type = matched_row['ì •ë¹„ì¢…ë¥˜'].iloc[0] if 'ì •ë¹„ì¢…ë¥˜' in df.columns and not matched_row.empty else 'N/A'
                        maint_person = matched_row['ì •ë¹„ì'].iloc[0] if 'ì •ë¹„ì' in df.columns and not matched_row.empty else 'N/A'


                        recommended.append({
                            "ì¡°ì¹˜": row["ì¡°ì¹˜"],
                            "ì„±ê³µë¥ ": row["ì„±ê³µë¥ (%)"],
                            "ì •ë¹„ë…¸íŠ¸": note,
                            "ì¥ë¹„ID": equip_id,
                            "ëª¨ë¸": model,
                            "ì •ë¹„ì¢…ë¥˜": maint_type,
                            "ì •ë¹„ì": maint_person
                        })


            if not recommended:
                st.warning("ê²€ìƒ‰ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # Top3 ì„ ì •
                def is_final_action(note: str):
                    return ("ì¶”ê°€ ì¡°ì¹˜" in note) or ("ì •ìƒ í™•ì¸" in note)


                final_candidates = [r for r in recommended if is_final_action(r["ì •ë¹„ë…¸íŠ¸"])]
                candidates_sorted = sorted(final_candidates, key=lambda x: x["ì„±ê³µë¥ "], reverse=True)


                top3 = []
                used_actions = set()
                used_notes = set()
                for r in candidates_sorted:
                    note_key = r["ì •ë¹„ë…¸íŠ¸"]
                    if r["ì¡°ì¹˜"] not in used_actions and note_key not in used_notes:
                        top3.append(r)
                        used_actions.add(r["ì¡°ì¹˜"])
                        used_notes.add(note_key)
                    if len(top3) == 3:
                        break


                if len(top3) < 3:
                    for r in sorted(recommended, key=lambda x: x["ì„±ê³µë¥ "], reverse=True):
                        if r["ì¡°ì¹˜"] not in used_actions and r["ì •ë¹„ë…¸íŠ¸"] not in used_notes:
                            top3.append(r)
                            used_actions.add(r["ì¡°ì¹˜"])
                            used_notes.add(r["ì •ë¹„ë…¸íŠ¸"])
                        if len(top3) == 3:
                            break


                # ----------------------
                # 3) LLM ì„¤ëª… ìƒì„±
                # ----------------------
                top3_desc = "\n".join([f"{i+1}. {r['ì¡°ì¹˜']} â€“ ì„±ê³µë¥  {r['ì„±ê³µë¥ ']}%"
                                       for i, r in enumerate(top3)])
                prompt = f"""
ë‹¤ìŒì€ ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì´ìŠˆì— ëŒ€í•œ Top3 ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜ ëª©ë¡ì…ë‹ˆë‹¤.
ê° ì¡°ì¹˜ì˜ ì˜ë¯¸ì™€ íŠ¹ì§•ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë‹¨ë½ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
ì„±ê³µë¥  ìˆ˜ì¹˜ëŠ” ë§í•˜ì§€ ë§ˆ.


{top3_desc}
                """
                explanation = llm.predict(prompt)
                top3_html = top3_desc.replace("\n", "<br>")


                # ì±—ë´‡ ë§í’ì„ 
                st.markdown(f"""
                <div style="display:flex; justify-content:flex-start; margin-bottom:10px;">
                    <div style="font-size:30px; margin-right:8px;">ğŸ¤–</div>
                    <div style="background-color:#F1F0F0; color:black; padding:10px 15px;
                                border-radius:15px; max-width:80%;">
                        âœ… Top3 ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜<br><br>
                        {top3_html}<br><br>
                        ğŸ’¡ {explanation}
                    </div>
                </div>
                """, unsafe_allow_html=True)


                # ----------------------
                # 4) ìƒì„¸ë³´ê¸°
                # ----------------------
                for idx, r in enumerate(top3, 1):
                    with st.expander(f"ğŸ”¹ Top{idx} ìƒì„¸ë³´ê¸° ({r['ì¡°ì¹˜']}, ì„±ê³µë¥  {r['ì„±ê³µë¥ ']}%)"):
                        note_html = r['ì •ë¹„ë…¸íŠ¸'].replace("\n", "<br>")
                        st.markdown(f"""
                        <div style="border:2px solid #B0C4DE; border-radius:8px;
                                    padding:15px; margin-bottom:10px;
                                    background-color:#F3F7FF;">
                            <b>ì¡°ì¹˜ëª…:</b> {r['ì¡°ì¹˜']}<br>
                            <b>ì¥ë¹„:</b> {r['ì¥ë¹„ID']} / {r['ëª¨ë¸']}<br>
                            <b>ì •ë¹„ì¢…ë¥˜:</b> {r['ì •ë¹„ì¢…ë¥˜']}<br>
                            <b>ì •ë¹„ì:</b> {r['ì •ë¹„ì']}<br><br>
                            <b>ì •ë¹„ë…¸íŠ¸:</b><br>
                            <div style="border:1px solid #ccc; padding:10px; margin-top:5px; background:#fff;">
                                {note_html}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)


# ----------------------
# 8. ì •ë¹„ í†µê³„ í˜ì´ì§€
# ----------------------
elif menu == "ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ":
    st.subheader("ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ")


    tab1, tab2, tab3 = st.tabs(["ğŸ† Top5 ìš”ì•½", "ğŸ“Š ì „ì²´ ìš”ì•½", "ğŸ”¹ ì¥ë¹„ë³„ ìƒì„¸"])


    # ----------------------
    # Tab1: Top5
    # ----------------------
    with tab1:
        with st.spinner("ğŸ“Š Top5 ìš”ì•½ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.subheader("ğŸ”§ ê°€ì¥ ë§ì´ ê³ ì¥ë‚œ ì¥ë¹„ TOP5")
            top5_equip = df['ëª¨ë¸'].value_counts().head(5)


            fig1 = px.pie(
                names=top5_equip.index.tolist(),
                values=top5_equip.values,
                hole=0.4
            )
            fig1.update_traces(textinfo='percent+label')
            st.plotly_chart(fig1, use_container_width=True)


            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nê° ì¥ë¹„ì˜ ê³ ì¥ íŒ¨í„´ê³¼ ë°œìƒ ê²½í–¥ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜ˆë°© ì •ë¹„ì™€ ê³µì • ìš´ì˜ ì¸¡ë©´ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ì¥ë¹„ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")


            # ë¬¸ì œì›ì¸ 10ê°œ ì •ì˜
            problem_keywords = [
                "wafer not", "plasma ignition failure", "pumpdown ì‹œê°„ ì§€ì—°",
                "mass flow controller ì´ìƒ", "etch residue over spec",
                "temperature abnormal", "slot valve ë™ì‘ ë¶ˆëŸ‰",
                "chamber leak", "sensor error", "RF auto match ë¶ˆëŸ‰"
            ]


            # TF-IDF ê¸°ë°˜ ë¬¸ì œì›ì¸ ë¶„ë¥˜ (ê¸°íƒ€ ì œê±°)
            from sklearn.feature_extraction.text import TfidfVectorizer
            from sklearn.metrics.pairwise import cosine_similarity


            notes = df['ì •ë¹„ë…¸íŠ¸'].astype(str).str.lower().tolist()
            corpus = notes + [kw.lower() for kw in problem_keywords]


            vectorizer = TfidfVectorizer()
            tfidf_matrix = vectorizer.fit_transform(corpus)


            note_vecs = tfidf_matrix[:-len(problem_keywords)]
            keyword_vecs = tfidf_matrix[-len(problem_keywords):]


            similarity_matrix = cosine_similarity(note_vecs, keyword_vecs)
            best_match_indices = similarity_matrix.argmax(axis=1)
            df['ë¬¸ì œì›ì¸'] = [problem_keywords[i] for i in best_match_indices]


            st.subheader("âš ï¸ ë¬¸ì œ ì›ì¸ TOP5")
            top5_cause = df['ë¬¸ì œì›ì¸'].value_counts().head(5)


            fig2 = px.bar(
                x=top5_cause.values,
                y=top5_cause.index,
                orientation='h',
                text=top5_cause.values,
                color=top5_cause.values,
                color_continuous_scale='OrRd'
            )
            fig2.update_traces(textposition='outside')
            st.plotly_chart(fig2, use_container_width=True)


            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_cause.index)}\nê° ë¬¸ì œ ì›ì¸ì˜ ì˜í–¥ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ì¤„ê¸€ ìš”ì•½í•´ì¤˜."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")


    # ----------------------
    # Tab2: ì „ì²´ ìš”ì•½
    # ----------------------
    with tab2:
        with st.spinner("ğŸ“Š ì „ì²´ ìš”ì•½ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.markdown("### ğŸ“Š ì „ì²´ ìš”ì•½")
            st.subheader("ğŸ§­ ì „ì²´ ì¥ë¹„ ê³ ì¥ ë¶„í¬")


            total_equip = df['ëª¨ë¸'].value_counts()


            fig_all = px.pie(
                names=total_equip.index.tolist(),
                values=total_equip.values,
                title="ì „ì²´ ì¥ë¹„ë³„ ê³ ì¥ ë¹„ìœ¨",
                hole=0.4
            )
            fig_all.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_all, use_container_width=True)


            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nëª¨ë“  ì¥ë¹„ì˜ ë¬¸ì œ ë°œìƒì„ ì „ì²´ì ì¸ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤. í•´ë‹¹ ë¹„ìœ¨ì„ ë¶„ì„í•´ë´¤ì„ ë•Œ, ì–»ì„ ìˆ˜ ìˆëŠ” ì¥ë¹„ì˜ ë¬¸ì œ ë°œìƒ ë¹„ìœ¨ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ì¤„ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ì¥ë¹„ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")


            st.subheader("ğŸ§  ì „ì²´ ë¬¸ì œ ì›ì¸ ë¶„í¬")


            total_cause = df['ë¬¸ì œì›ì¸'].value_counts()


            fig_cause = px.pie(
                names=total_cause.index.tolist(),
                values=total_cause.values,
                title="ì „ì²´ ë¬¸ì œ ì›ì¸ë³„ ê³ ì¥ ë¹„ìœ¨",
                hole=0.4
            )
            fig_cause.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_cause, use_container_width=True)


            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nëª¨ë“  ë¬¸ì œì˜ ì›ì¸ì„ ì „ì²´ì ì¸ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤. í•´ë‹¹ ë¹„ìœ¨ì„ ë¶„ì„í•´ë´¤ì„ ë•Œ, ì–»ì„ ìˆ˜ ìˆëŠ” ë¬¸ì œ ë°œìƒì›ì¸ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ì¤„ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ë¬¸ì œ ì›ì¸ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")


    # ----------------------
    # Tab3: ì¥ë¹„ë³„ ìƒì„¸
    # ----------------------
    with tab3:
        with st.spinner("ğŸ“Š ì¥ë¹„ë³„ ìƒì„¸ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.markdown("### ğŸ”¹ ì¥ë¹„ë³„ ìƒì„¸")


            problem_keywords = [
                "wafer not", "plasma ignition failure", "pumpdown ì‹œê°„ ì§€ì—°",
                "mass flow controller ì´ìƒ", "etch residue over spec",
                "temperature drift", "slot valve ë™ì‘ ë¶ˆëŸ‰",
                "chamber pressure fluctuation", "he flow deviation", "RF auto match ë¶ˆëŸ‰"
            ]
            alias_map = {
                "wafer not ê°ì§€ë¨": "wafer not",
                "wafer not ë°œìƒ": "wafer not",
                "rf auto match fail": "RF auto match ë¶ˆëŸ‰",
                "slot valve ë¶ˆëŸ‰": "slot valve ë™ì‘ ë¶ˆëŸ‰",
                "he flow dev": "he flow deviation",
            }


            def normalize_note(note: str) -> str:
                note = str(note).lower()
                note = re.sub(r'\s+', ' ', note)
                return note


            def extract_cause(note: str):
                note_low = normalize_note(note)
                for alias, norm in alias_map.items():
                    if alias in note_low:
                        return norm
                for keyword in problem_keywords:
                    if keyword.lower() in note_low:
                        return keyword
                return "ê¸°íƒ€"


            df['ë¬¸ì œì›ì¸'] = df['ì •ë¹„ë…¸íŠ¸'].apply(extract_cause)


            equip_list = df['ëª¨ë¸'].dropna().unique().tolist()
            selected_equip = st.selectbox("ì¥ë¹„ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + equip_list)


            if selected_equip != "ì „ì²´":
                df_filtered = df[df['ëª¨ë¸'] == selected_equip]


                if df_filtered.empty:
                    st.warning(f"ì„ íƒí•œ ì¥ë¹„({selected_equip})ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    top5_cause_equip = (
                        df_filtered.groupby('ë¬¸ì œì›ì¸')
                        .size()
                        .reset_index(name='ë¹ˆë„')
                        .sort_values('ë¹ˆë„', ascending=False)
                        .head(5)
                    )


                    st.subheader(f"âš¡ {selected_equip} ë¬¸ì œ ì›ì¸ TOP5")
                    fig3 = px.bar(
                        x=top5_cause_equip['ë¹ˆë„'],
                        y=top5_cause_equip['ë¬¸ì œì›ì¸'],
                        orientation='h',
                        text=top5_cause_equip['ë¹ˆë„'],
                        color=top5_cause_equip['ë¹ˆë„'],
                        color_continuous_scale='Purples'
                    )
                    fig3.update_traces(textposition='outside')
                    st.plotly_chart(fig3, use_container_width=True)


                    selected_cause = st.selectbox(
                        "ë¬¸ì œ ì›ì¸ì„ ì„ íƒí•˜ì„¸ìš”",
                        top5_cause_equip['ë¬¸ì œì›ì¸'].tolist()
                    )


                    if selected_cause:
                        df_cause = df_success[df_success['ëŒ€í‘œì›ì¸'] == selected_cause]
                        top3_actions = (
                            df_cause.sort_values('ì„±ê³µë¥ (%)', ascending=False)
                            .head(3)[['ì¡°ì¹˜']]
                        )


                        if top3_actions.empty:
                            st.info(f"'{selected_cause}'ì— ëŒ€í•œ ì¶”ì²œ ì¡°ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.markdown(f"### ğŸ¤– '{selected_cause}' ì¶”ì²œ ì¡°ì¹˜ TOP3")
                            for idx, row in top3_actions.iterrows():
                                st.markdown(f"- {row['ì¡°ì¹˜']}")
            else:
                st.info("ì¥ë¹„ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì¥ë¹„ì˜ ë¬¸ì œ ì›ì¸ê³¼ ì¶”ì²œ ì¡°ì¹˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.") 