import os
import sys
import streamlit as st
from dotenv import load_dotenv
import faiss
import pandas as pd
import re
from collections import defaultdict, Counter
import plotly.express as px
import base64
from langchain.docstore.document import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from multiprocessing import Pool  # ë³‘ë ¬ ì²˜ë¦¬ ì¶”ê°€
import seaborn as sns  # íˆíŠ¸ë§µ ì¶”ê°€
import matplotlib.pyplot as plt  # íˆíŠ¸ë§µ ì¶”ê°€

# ë²„ì „ í™•ì¸
st.write(f"Python version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env)
load_dotenv()

# ë¡œê³  ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
def get_base64_of_bin_file(bin_file_path):
    with open(bin_file_path, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

logo_path = "Hero_logo(final).png"  # ì‹¤í–‰ í´ë” ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ
logo_base64 = get_base64_of_bin_file(logo_path)

# ----------------------------
# 0. Streamlit ì„¤ì •
# ----------------------------
st.set_page_config(page_title="ğŸš€mySUNI X SK í”„ë¡œì íŠ¸", layout="wide")

# ìƒë‹¨ ë¹¨ê°„ìƒ‰ ë¼ì¸ + ë¡œê³ /ì œëª© ì˜ì—­
st.markdown(
    f"""
    <div style="background-color:#ff4b4b; height:30px; width:100%;"></div>
    <div style="display:flex; align-items:center; padding:20px 30px;">
        <img src="data:image/png;base64,{logo_base64}" alt="logo" style="height:100px; margin-right:30px;">
        <div>
            <h1 style="margin:0; font-size:2.5rem; color:#222;">HERO</h1>
            <p style="margin:0; font-size:1.1rem; color:#555;">Hynix Equipment Response Operator</p>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# ----------------------------
# 0.1 ë¡œê·¸ì¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ----------------------------
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "api_key" not in st.session_state:
    st.session_state.api_key = None

# ----------------------------
# 1. ë¡œê·¸ì¸ ë‹¨ê³„
# ----------------------------
if not st.session_state.logged_in:
    st.subheader("ğŸ”‘ ë¡œê·¸ì¸")

    username = st.text_input("ì•„ì´ë””")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")

    valid_users = {
        "mySUNI250728!@": "mySUNI250728!@",
    }

    if st.button("ë¡œê·¸ì¸"):
        if username in valid_users and password == valid_users[username]:
            st.session_state.logged_in = True
            st.session_state.username = username
            st.session_state.api_key = st.secrets["OPENAI_API_KEY"]
            st.success(f"âœ… {username}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!")
            st.rerun()
        else:
            st.error("âŒ ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# ----------------------------
# OpenAI API í‚¤ í™˜ê²½ë³€ìˆ˜ ì„¸íŒ…
# ----------------------------
if st.session_state.api_key and isinstance(st.session_state.api_key, str):
    os.environ["OPENAI_API_KEY"] = st.session_state.api_key
else:
    api_key_env = os.getenv("OPENAI_API_KEY")
    if api_key_env:
        os.environ["OPENAI_API_KEY"] = api_key_env
    else:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë¡œê·¸ì¸ í›„ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

# ë©”ì¸ íƒ€ì´í‹€ (ë¡œê·¸ì¸ í›„ ìµœìƒë‹¨)
st.markdown("<h2 style='color:#000000; font-weight:bold;'>í•˜ì´ë‹‰ìŠ¤ ì¥ë¹„ ë¬¸ì œ, HEROì™€ í•¨ê»˜ í•´ê²°í•´ìš”!</h2>", unsafe_allow_html=True)

# ----------------------------
# 2. ì—‘ì…€ ì—…ë¡œë“œ
# ----------------------------
uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])
if uploaded_file is None:
    st.info("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    st.stop()

with st.spinner("ğŸ“‚ íŒŒì¼ ì½ê¸°/ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì˜¤ë˜ ê±¸ë ¤ìš”..."):
    df = pd.read_excel(uploaded_file)
    if 'ì •ë¹„ì¼ì' in df.columns:
        df['ì •ë¹„ì¼ì'] = pd.to_datetime(df['ì •ë¹„ì¼ì'], errors='coerce')

    df = df.dropna(subset=['ì •ë¹„ë…¸íŠ¸'])
    st.success(f"ì—…ë¡œë“œ ì™„ë£Œ: ì´ {len(df)} í–‰")

# ----------------------------
# 3. ë¬¸ì œ ì›ì¸ ì»¬ëŸ¼ ìƒì„± (ì—‘ì…€ ì—…ë¡œë“œ ì§í›„)
# ----------------------------
problem_keywords = [
    "wafer not", "plasma ignition failure", "pumpdown ì‹œê°„ ì§€ì—°",
    "mass flow controller ì´ìƒ", "etch residue over spec",
    "temperature drift", "slot valve ë™ì‘ ë¶ˆëŸ‰",
    "chamber pressure fluctuation", "he flow deviation", "RF auto match ë¶ˆëŸ‰"
]
alias_map = {
    "wafer not ê°ì§€ë¨": "wafer not",
    "wafer not ë°œìƒ": "wafer not",
    "rf auto match fail": "RF auto match ë¶ˆëŸ‰",
    "slot valve ë¶ˆëŸ‰": "slot valve ë™ì‘ ë¶ˆëŸ‰",
    "he flow dev": "he flow deviation",
}

def normalize_note(note: str) -> str:
    note = str(note).lower()
    note = re.sub(r'\s+', ' ', note)
    return note

def extract_cause(note: str):
    note_low = normalize_note(note)
    for alias, norm in alias_map.items():
        if alias in note_low:
            return norm
    for keyword in problem_keywords:
        if keyword.lower() in note_low:
            return keyword
    return "ê¸°íƒ€"

# ë³‘ë ¬ ì²˜ë¦¬ ì¶”ê°€
def process_chunk(chunk):
    return [extract_cause(note) for note in chunk]

chunks = [df['ì •ë¹„ë…¸íŠ¸'][i:i + 100] for i in range(0, len(df['ì •ë¹„ë…¸íŠ¸']), 100)]
with Pool() as pool:
    results = pool.map(process_chunk, chunks)
df['ë¬¸ì œì›ì¸'] = [item for sublist in results for item in sublist]

# ----------------------------
# 4. ì •ë¹„ë…¸íŠ¸ ê¸°ë°˜ ì„±ê³µë¥  ê³„ì‚°
# ----------------------------
all_texts = [str(note).strip() for note in df['ì •ë¹„ë…¸íŠ¸']]

cause_pattern = re.compile(r'LOT ì§„í–‰ ì¤‘ (.+) ë°œìƒ')
first_action_pattern = re.compile(r'1ì°¨ ì¡°ì¹˜: (.+) â†’ ì—¬ì „íˆ ì´ìƒ ë°œìƒ')
second_action_pattern = re.compile(r'ì •ë¹„ ì‹œì‘\. (.+) ì§„í–‰')
third_action_pattern = re.compile(r'ì¶”ê°€ ì¡°ì¹˜: (.+)')

cause_aliases = {
    "wafer not ë°œìƒ": "wafer not",
    "wafer not ê°ì§€ë¨": "wafer not",
    "wafer not ë°œìƒ í™•ì¸": "wafer not",
}

def normalize_cause(cause):
    for alias, norm in cause_aliases.items():
        if alias in cause:
            return norm
    return cause

cause_action_counts = defaultdict(lambda: defaultdict(Counter))
note_map = defaultdict(list)

for idx, note in enumerate(all_texts):
    lines = [line.strip() for line in note.split('\n') if line.strip()]
    cause = None
    for line in lines:
        cause_match = cause_pattern.search(line)
        if cause_match:
            cause = normalize_cause(cause_match.group(1).strip())
            continue
        if cause is None:
            continue

        action = None
        m1 = first_action_pattern.search(line)
        m2 = second_action_pattern.search(line)
        m3 = third_action_pattern.search(line)

        if m1:
            action = m1.group(1).strip()
            cause_action_counts[cause][action]['first'] += 1
        elif m2:
            action = m2.group(1).strip()
            cause_action_counts[cause][action]['second'] += 1
        elif m3:
            action = m3.group(1).strip()
            cause_action_counts[cause][action]['third'] += 1

        if action:
            note_map[(cause, action)].append(note)

rows = []
for cause, actions in cause_action_counts.items():
    for action, counts in actions.items():
        first_count = counts['first']
        second_count = counts['second']
        third_count = counts['third']
        total = first_count + second_count + third_count
        success = second_count + third_count
        success_rate = round(success / total * 100, 2) if total > 0 else 0

        rows.append({
            "ëŒ€í‘œì›ì¸": cause,
            "ì¡°ì¹˜": action,
            "ì´íšŸìˆ˜": total,
            "ì‹¤íŒ¨íšŸìˆ˜": first_count,
            "ì„±ê³µíšŸìˆ˜": success,
            "ì„±ê³µë¥ (%)": success_rate,
            "ì •ë¹„ë…¸íŠ¸": note_map[(cause, action)][0] if note_map[(cause, action)] else ""
        })

df_success = pd.DataFrame(rows)

# ----------------------------
# 5. LangChain RAG ì¤€ë¹„ (ì„ë² ë”© ë° ë²¡í„° DB ìƒì„±, ì„¸ì…˜ ìºì‹± í¬í•¨)
documents = [
    Document(page_content=str(row['ì •ë¹„ë…¸íŠ¸']), metadata={'row': idx})
    for idx, row in df.iterrows()
]

splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(documents)

INDEX_PATH = "faiss_index.index"  # ì €ì¥í•  ì¸ë±ìŠ¤ íŒŒì¼ëª…

from langchain.docstore import InMemoryDocstore

def load_or_create_vectordb(documents, embedding_model):
    if os.path.exists(INDEX_PATH):
        index = faiss.read_index(INDEX_PATH)
        index_to_docstore_id = {i: str(i) for i in range(len(documents))}
        docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})
        vectordb = FAISS(
            embedding_function=embedding_model.embed_query,
            index=index,
            docstore=docstore,
            index_to_docstore_id=index_to_docstore_id
        )
    else:
        vectordb = FAISS.from_documents(documents, embedding_model)
        faiss.write_index(vectordb.index, INDEX_PATH)
    return vectordb

# ì„ë² ë”© ìƒì„± ì¤‘ ë‹¨ê³„ë³„ ì§„í–‰ ìƒíƒœ í‘œì‹œ ì¶”ê°€
if "embedding_model" not in st.session_state or "vectordb" not in st.session_state:
    with st.spinner("ğŸ” ì„ë² ë”© ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
        st.write("1/3 ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
        embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")
        
        st.write("2/3 ë‹¨ê³„: ë²¡í„° DB ìƒì„± ì¤‘...")
        vectordb = load_or_create_vectordb(split_docs, embedding_model)
        
        st.write("3/3 ë‹¨ê³„: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì¤‘...")
        st.session_state["embedding_model"] = embedding_model
        st.session_state["vectordb"] = vectordb
else:
    embedding_model = st.session_state["embedding_model"]
    vectordb = st.session_state["vectordb"]

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(search_kwargs={'k': 20}),
    return_source_documents=True
)

# ----------------------
# 6. ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
menu = st.sidebar.radio(
    "ğŸ“‚ ë©”ë‰´ ì„ íƒ",
    ["ğŸ”¹ ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ", "ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ"]
)

# ----------------------
# 7. ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ í˜ì´ì§€
# ----------------------
if menu == "ğŸ”¹ ì •ë¹„ ê²€ìƒ‰ & ì¶”ì²œ":
    st.subheader("ğŸ¤– HERO ì±—ë´‡ â€“ ì •ë¹„ ë¬¸ì œ, ì œê°€ ë‹¤ ì•Œê³ ìˆì–´ìš”!")

    example_keywords = [
        "wafer not", "plasma ignition failure",
        "pumpdown ì‹œê°„ ì§€ì—°", "slot valve ë™ì‘ ë¶ˆëŸ‰",
        "RF auto match ë¶ˆëŸ‰"
    ]

    st.markdown(f"""
    <div style="display:flex; justify-content:flex-start; margin-bottom:10px;">
        <div style="font-size:30px; margin-right:8px;">ğŸ¤–</div>
        <div style="background-color:#F1F0F0; color:black; padding:10px 15px;
                    border-radius:15px; max-width:80%;">
            ì•ˆë…•í•˜ì„¸ìš”ğŸ‘‹<br>
            ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì´ìŠˆ í•´ê²° ë„ìš°ë¯¸ HEROì…ë‹ˆë‹¤!<br>
            ì •ë¹„ ì´ìŠˆë¥¼ ì…ë ¥í•˜ì‹œë©´, HEROê°€ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì•„ í•´ê²°ì±…ì„ ì œì•ˆí•´ë“œë ¤ìš”.<br><br>
            ğŸ’¡ {' | '.join(example_keywords)}
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ê²€ìƒ‰ì–´ ìë™ ì™„ì„± ê¸°ëŠ¥ ì¶”ê°€
    from streamlit_searchbox import st_searchbox

    def search_suggestions(search_term):
        return [kw for kw in problem_keywords if search_term.lower() in kw.lower()]

    query = st_searchbox(
        search_suggestions,
        key="search_query",
        placeholder="ì˜ˆ: slot valve ë™ì‘ì´ ì•ˆë¼ã… ã… "
    )

    # âœ… ì…ë ¥ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
    if query.strip():
        with st.spinner("ğŸ”„ ìœ ì‚¬ ì •ë¹„ ì‚¬ë¡€ì™€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            # ì‚¬ìš©ì ë§í’ì„ 
            st.markdown(f"""
            <div style="display:flex; justify-content:flex-end; margin-bottom:10px;">
                <div style="background-color:#DCF8C6; color:black;
                            padding:10px 15px; border-radius:15px;
                            max-width:70%; text-align:right;">
                    {query}
                </div>
                <div style="font-size:30px; margin-left:8px;">ğŸ‘¤</div>
            </div>
            """, unsafe_allow_html=True)

            # ----------------------
            # 1) RAG ê²€ìƒ‰
            # ----------------------
            output = qa_chain({"query": query})
            docs = output['source_documents']

            recommended = []
            seen_pairs = set()

            for doc in docs:
                note = doc.page_content.strip()
                for _, row in df_success.iterrows():
                    if row["ì¡°ì¹˜"] in note:
                        key = (row["ì¡°ì¹˜"], note)
                        if key in seen_pairs:
                            continue
                        seen_pairs.add(key)

                        matched_row = df[df['ì •ë¹„ë…¸íŠ¸'].astype(str).str.strip() == note]
                        equip_id = matched_row['ì¥ë¹„ID'].iloc[0] if 'ì¥ë¹„ID' in df.columns and not matched_row.empty else 'N/A'
                        model = matched_row['ëª¨ë¸'].iloc[0] if 'ëª¨ë¸' in df.columns and not matched_row.empty else 'N/A'
                        maint_type = matched_row['ì •ë¹„ì¢…ë¥˜'].iloc[0] if 'ì •ë¹„ì¢…ë¥˜' in df.columns and not matched_row.empty else 'N/A'
                        maint_person = matched_row['ì •ë¹„ì'].iloc[0] if 'ì •ë¹„ì' in df.columns and not matched_row.empty else 'N/A'

                        recommended.append({
                            "ì¡°ì¹˜": row["ì¡°ì¹˜"],
                            "ì„±ê³µë¥ ": row["ì„±ê³µë¥ (%)"],
                            "ì •ë¹„ë…¸íŠ¸": note,
                            "ì¥ë¹„ID": equip_id,
                            "ëª¨ë¸": model,
                            "ì •ë¹„ì¢…ë¥˜": maint_type,
                            "ì •ë¹„ì": maint_person
                        })

            if not recommended:
                st.warning("ê²€ìƒ‰ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # Top3 ì„ ì •
                def is_final_action(note: str):
                    return ("ì¶”ê°€ ì¡°ì¹˜" in note) or ("ì •ìƒ í™•ì¸" in note)

                final_candidates = [r for r in recommended if is_final_action(r["ì •ë¹„ë…¸íŠ¸"])]
                candidates_sorted = sorted(final_candidates, key=lambda x: x["ì„±ê³µë¥ "], reverse=True)

                top3 = []
                used_actions = set()
                used_notes = set()
                for r in candidates_sorted:
                    note_key = r["ì •ë¹„ë…¸íŠ¸"]
                    if r["ì¡°ì¹˜"] not in used_actions and note_key not in used_notes:
                        top3.append(r)
                        used_actions.add(r["ì¡°ì¹˜"])
                        used_notes.add(note_key)
                    if len(top3) == 3:
                        break

                if len(top3) < 3:
                    for r in sorted(recommended, key=lambda x: x["ì„±ê³µë¥ "], reverse=True):
                        if r["ì¡°ì¹˜"] not in used_actions and r["ì •ë¹„ë…¸íŠ¸"] not in used_notes:
                            top3.append(r)
                            used_actions.add(r["ì¡°ì¹˜"])
                            used_notes.add(r["ì •ë¹„ë…¸íŠ¸"])
                        if len(top3) == 3:
                            break

                # ----------------------
                # 3) LLM ì„¤ëª… ìƒì„±
                # ----------------------
                top3_desc = "\n".join([f"{i+1}. {r['ì¡°ì¹˜']} â€“ ì„±ê³µë¥  {r['ì„±ê³µë¥ ']}%"
                                       for i, r in enumerate(top3)])
                prompt = f"""
ë‹¤ìŒì€ ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì´ìŠˆì— ëŒ€í•œ Top3 ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜ ëª©ë¡ì…ë‹ˆë‹¤.
ê° ì¡°ì¹˜ì˜ ì˜ë¯¸ì™€ íŠ¹ì§•ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë‹¨ë½ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
ì„±ê³µë¥  ìˆ˜ì¹˜ëŠ” ë§í•˜ì§€ ë§ˆ.

{top3_desc}
                """
                explanation = llm.predict(prompt)
                top3_html = top3_desc.replace("\n", "<br>")

                # ì±—ë´‡ ë§í’ì„ 
                st.markdown(f"""
                <div style="display:flex; justify-content:flex-start; margin-bottom:10px;">
                    <div style="font-size:30px; margin-right:8px;">ğŸ¤–</div>
                    <div style="background-color:#F1F0F0; color:black; padding:10px 15px;
                                border-radius:15px; max-width:80%;">
                        âœ… Top3 ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜<br><br>
                        {top3_html}<br><br>
                        ğŸ’¡ {explanation}
                    </div>
                </div>
                """, unsafe_allow_html=True)

                # ----------------------
                # 4) ìƒì„¸ë³´ê¸°
                # ----------------------
                for idx, r in enumerate(top3, 1):
                    with st.expander(f"ğŸ”¹ Top{idx} ìƒì„¸ë³´ê¸° ({r['ì¡°ì¹˜']}, ì„±ê³µë¥  {r['ì„±ê³µë¥ ']}%)"):
                        note_html = r['ì •ë¹„ë…¸íŠ¸'].replace("\n", "<br>")
                        st.markdown(f"""
                        <div style="border:2px solid #B0C4DE; border-radius:8px;
                                    padding:15px; margin-bottom:10px;
                                    background-color:#F3F7FF;">
                            <b>ì¡°ì¹˜ëª…:</b> {r['ì¡°ì¹˜']}<br>
                            <b>ì¥ë¹„:</b> {r['ì¥ë¹„ID']} / {r['ëª¨ë¸']}<br>
                            <b>ì •ë¹„ì¢…ë¥˜:</b> {r['ì •ë¹„ì¢…ë¥˜']}<br>
                            <b>ì •ë¹„ì:</b> {r['ì •ë¹„ì']}<br><br>
                            <b>ì •ë¹„ë…¸íŠ¸:</b><br>
                            <div style="border:1px solid #ccc; padding:10px; margin-top:5px; background:#fff;">
                                {note_html}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

# ----------------------
# 8. ì •ë¹„ í†µê³„ í˜ì´ì§€
# ----------------------
elif menu == "ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ":
    st.subheader("ğŸ“ˆ ì •ë¹„ í†µê³„ ìë£Œ")

    tab1, tab2, tab3 = st.tabs(["ğŸ† Top5 ìš”ì•½", "ğŸ“Š ì „ì²´ ìš”ì•½", "ğŸ”¹ ì¥ë¹„ë³„ ìƒì„¸"])

    # ----------------------
    # Tab1: Top5
    # ----------------------
    with tab1:
        with st.spinner("ğŸ“Š Top5 ìš”ì•½ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.subheader("ğŸ”§ ê°€ì¥ ë§ì´ ê³ ì¥ë‚œ ì¥ë¹„ TOP5")
            top5_equip = df['ëª¨ë¸'].value_counts().head(5)

            fig1 = px.bar(
                x=top5_equip.values,
                y=top5_equip.index,
                orientation='h',
                text=[f"{v}ê±´" for v in top5_equip.values],
                color=top5_equip.values,
                color_continuous_scale='Blues'
            )
            fig1.update_traces(textposition='outside')
            st.plotly_chart(fig1, use_container_width=True)

            # ìƒì„¸ ì •ë³´ í‘œì‹œ ì¶”ê°€
            selected_bar = st.selectbox("ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”", top5_equip.index)
            if selected_bar:
                st.write(f"ì„ íƒëœ í•­ëª©: {selected_bar}")
                st.write(df[df['ëª¨ë¸'] == selected_bar].head())

            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nê° ì¥ë¹„ì˜ ê³ ì¥ íŒ¨í„´ê³¼ ë°œìƒ ê²½í–¥ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜ˆë°© ì •ë¹„ì™€ ê³µì • ìš´ì˜ ì¸¡ë©´ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ì¥ë¹„ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")

            st.subheader("âš ï¸ ë¬¸ì œ ì›ì¸ TOP5")
            top5_cause = df['ë¬¸ì œì›ì¸'].value_counts().head(5)

            fig2 = px.bar(
                x=top5_cause.values,
                y=top5_cause.index,
                orientation='h',
                text=[f"{v}ê±´" for v in top5_cause.values],
                color=top5_cause.values,
                color_continuous_scale='OrRd'
            )
            fig2.update_traces(textposition='outside')
            st.plotly_chart(fig2, use_container_width=True)

            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_cause.index)}\nê° ë¬¸ì œ ì›ì¸ì˜ ì˜í–¥ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ì¤„ê¸€ ìš”ì•½í•´ì¤˜."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")

    # ----------------------
    # Tab2: ì „ì²´ ìš”ì•½
    # ----------------------
    with tab2:
        with st.spinner("ğŸ“Š ì „ì²´ ìš”ì•½ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.markdown("### ğŸ“Š ì „ì²´ ìš”ì•½")
            st.subheader("ğŸ§­ ì „ì²´ ì¥ë¹„ ê³ ì¥ ë¶„í¬")

            total_equip = df['ëª¨ë¸'].value_counts()

            fig_all = px.pie(
                names=total_equip.index.tolist(),
                values=total_equip.values,
                title="ì „ì²´ ì¥ë¹„ë³„ ê³ ì¥ ë¹„ìœ¨",
                hole=0.4
            )
            fig_all.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_all, use_container_width=True)

            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nëª¨ë“  ì¥ë¹„ì˜ ë¬¸ì œ ë°œìƒì„ ì „ì²´ì ì¸ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤. í•´ë‹¹ ë¹„ìœ¨ì„ ë¶„ì„í•´ë´¤ì„ ë•Œ, ì–»ì„ ìˆ˜ ìˆëŠ” ì¥ë¹„ì˜ ë¬¸ì œ ë°œìƒ ë¹„ìœ¨ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ì¤„ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ì¥ë¹„ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")

            st.subheader("ğŸ§  ì „ì²´ ë¬¸ì œ ì›ì¸ ë¶„í¬")

            total_cause = df['ë¬¸ì œì›ì¸'].value_counts()

            fig_cause = px.pie(
                names=total_cause.index.tolist(),
                values=total_cause.values,
                title="ì „ì²´ ë¬¸ì œ ì›ì¸ë³„ ê³ ì¥ ë¹„ìœ¨",
                hole=0.4
            )
            fig_cause.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_cause, use_container_width=True)

            prompt_cause = f"ë¬¸ì œ ì›ì¸: {', '.join(top5_equip.index)}\nëª¨ë“  ë¬¸ì œì˜ ì›ì¸ì„ ì „ì²´ì ì¸ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤. í•´ë‹¹ ë¹„ìœ¨ì„ ë¶„ì„í•´ë´¤ì„ ë•Œ, ì–»ì„ ìˆ˜ ìˆëŠ” ë¬¸ì œ ë°œìƒì›ì¸ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ 2~3ì¤„ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. 1~3ìœ„ ì •ë„ëŠ” ë¬¸ì œ ì›ì¸ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”."
            insight_cause = llm.predict(prompt_cause)
            st.markdown(f"ğŸ’¡ **ë¬¸ì œ ì›ì¸ ì¸ì‚¬ì´íŠ¸:** {insight_cause}")

    # ----------------------
    # Tab3: ì¥ë¹„ë³„ ìƒì„¸
    # ----------------------
    with tab3:
        with st.spinner("ğŸ“Š ì¥ë¹„ë³„ ìƒì„¸ ë°ì´í„°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.markdown("### ğŸ”¹ ì¥ë¹„ë³„ ìƒì„¸")

            equip_list = df['ëª¨ë¸'].dropna().unique().tolist()
            selected_equip = st.selectbox("ì¥ë¹„ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + equip_list)

            if selected_equip != "ì „ì²´":
                df_filtered = df[df['ëª¨ë¸'] == selected_equip]

                if df_filtered.empty:
                    st.warning(f"ì„ íƒí•œ ì¥ë¹„({selected_equip})ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    top5_cause_equip = (
                        df_filtered.groupby('ë¬¸ì œì›ì¸')
                        .size()
                        .reset_index(name='ë¹ˆë„')
                        .sort_values('ë¹ˆë„', ascending=False)
                        .head(5)
                    )

                    st.subheader(f"âš¡ {selected_equip} ë¬¸ì œ ì›ì¸ TOP5")
                    fig3 = px.bar(
                        x=top5_cause_equip['ë¹ˆë„'],
                        y=top5_cause_equip['ë¬¸ì œì›ì¸'],
                        orientation='h',
                        text=top5_cause_equip['ë¹ˆë„'],
                        color=top5_cause_equip['ë¹ˆë„'],
                        color_continuous_scale='Purples'
                    )
                    fig3.update_traces(textposition='outside')
                    st.plotly_chart(fig3, use_container_width=True)

                    selected_cause = st.selectbox(
                        "ë¬¸ì œ ì›ì¸ì„ ì„ íƒí•˜ì„¸ìš”",
                        top5_cause_equip['ë¬¸ì œì›ì¸'].tolist()
                    )

                    if selected_cause:
                        df_cause = df_success[df_success['ëŒ€í‘œì›ì¸'] == selected_cause]
                        top3_actions = (
                            df_cause.sort_values('ì„±ê³µë¥ (%)', ascending=False)
                            .head(3)[['ì¡°ì¹˜']]
                        )

                        if top3_actions.empty:
                            st.info(f"'{selected_cause}'ì— ëŒ€í•œ ì¶”ì²œ ì¡°ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.markdown(f"### ğŸ¤– '{selected_cause}' ì¶”ì²œ ì¡°ì¹˜ TOP3")
                            for idx, row in top3_actions.iterrows():
                                st.markdown(f"- {row['ì¡°ì¹˜']}")
            else:
                st.info("ì¥ë¹„ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì¥ë¹„ì˜ ë¬¸ì œ ì›ì¸ê³¼ ì¶”ì²œ ì¡°ì¹˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # íˆíŠ¸ë§µ ì¶”ê°€
            st.subheader("ğŸ”¥ ì¥ë¹„ë³„ ë¬¸ì œ ì›ì¸ ë¹ˆë„ íˆíŠ¸ë§µ")
            heatmap_data = df.pivot_table(index='ëª¨ë¸', columns='ë¬¸ì œì›ì¸', aggfunc='size', fill_value=0)
            plt.figure(figsize=(10, 6))
            sns.heatmap(heatmap_data, annot=True, fmt="d", cmap="YlOrRd")
            plt.title("ì¥ë¹„ë³„ ë¬¸ì œ ì›ì¸ ë¹ˆë„ íˆíŠ¸ë§µ")
            st.pyplot(plt)
