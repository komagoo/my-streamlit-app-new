import os
import sys
import streamlit as st
from dotenv import load_dotenv
import faiss

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env)
load_dotenv()

# ì¼ë°˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import re
from collections import defaultdict, Counter
import plotly.express as px
import base64

# Langchain ê´€ë ¨
from langchain.docstore.document import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ë¡œê³  ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except:
        return None

logo_path = "Hero_logo(final).png"
logo_base64 = get_base64_of_bin_file(logo_path)

# ----------------------------
# 0. Streamlit ì„¤ì •
# ----------------------------
st.set_page_config(
    page_title="ğŸš€ HERO - Hynix Equipment Response Operator", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #ff4b4b, #ff6b6b);
        color: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 30px;
    }
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 20px;
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        background-color: #fafafa;
    }
    .user-message {
        background-color: #DCF8C6;
        padding: 10px 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-left: 20%;
        text-align: right;
    }
    .bot-message {
        background-color: #F1F0F0;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-right: 20%;
    }
    .success-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .metric-card {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        margin: 10px;
    }
    .stTab {
        background-color: white;
        border-radius: 10px;
        padding: 20px;
    }
</style>
""", unsafe_allow_html=True)

# í—¤ë” ì„¹ì…˜
if logo_base64:
    st.markdown(f"""
    <div class="main-header">
        <div style="display:flex; align-items:center; justify-content:center;">
            <img src="data:image/png;base64,{logo_base64}" alt="HERO Logo" style="height:80px; margin-right:20px;">
            <div>
                <h1 style="margin:0; font-size:2.5rem;">HERO</h1>
                <p style="margin:0; font-size:1.2rem; opacity:0.9;">Hynix Equipment Response Operator</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
else:
    st.markdown("""
    <div class="main-header">
        <h1 style="margin:0; font-size:2.5rem;">ğŸš€ HERO</h1>
        <p style="margin:0; font-size:1.2rem; opacity:0.9;">Hynix Equipment Response Operator</p>
    </div>
    """, unsafe_allow_html=True)

# ----------------------------
# ë¡œê·¸ì¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ----------------------------
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "api_key" not in st.session_state:
    st.session_state.api_key = None

# ----------------------------
# 1. ë¡œê·¸ì¸ ë‹¨ê³„
# ----------------------------
if not st.session_state.logged_in:
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        <div style="background-color: white; padding: 40px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <h2 style="text-align: center; color: #333; margin-bottom: 30px;">ğŸ” ë¡œê·¸ì¸</h2>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_form"):
            username = st.text_input("ğŸ‘¤ ì•„ì´ë””", placeholder="ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            password = st.text_input("ğŸ”’ ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            
            submitted = st.form_submit_button("ğŸš€ ë¡œê·¸ì¸", use_container_width=True)
            
            if submitted:
                valid_users = {"mySUNI250728!@": "mySUNI250728!@"}
                
                if username in valid_users and password == valid_users[username]:
                    st.session_state.logged_in = True
                    st.session_state.username = username
                    st.session_state.api_key = st.secrets["OPENAI_API_KEY"]
                    st.success(f"âœ… {username}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!")
                    st.rerun()
                else:
                    st.error("âŒ ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# ----------------------------
# OpenAI API í‚¤ í™˜ê²½ë³€ìˆ˜ ì„¸íŒ…
# ----------------------------
if st.session_state.api_key and isinstance(st.session_state.api_key, str):
    os.environ["OPENAI_API_KEY"] = st.session_state.api_key
else:
    api_key_env = os.getenv("OPENAI_API_KEY")
    if api_key_env:
        os.environ["OPENAI_API_KEY"] = api_key_env
    else:
        st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

# ì‚¬ì´ë“œë°” - ì‚¬ìš©ì ì •ë³´ ë° ë¡œê·¸ì•„ì›ƒ
with st.sidebar:
    st.markdown(f"""
    <div style="background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin-bottom: 20px;">
        <h4 style="margin: 0; color: #333;">ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!</h4>
        <p style="margin: 5px 0 0 0; color: #666;">{st.session_state.username}</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()

# ----------------------------
# 2. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
# ----------------------------
st.markdown("### ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")

col1, col2 = st.columns([2, 1])

with col1:
    uploaded_file = st.file_uploader(
        "ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.xlsx)", 
        type=["xlsx"],
        help="ì •ë¹„ë…¸íŠ¸ê°€ í¬í•¨ëœ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )

with col2:
    if uploaded_file:
        st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
    else:
        st.info("ğŸ“¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”")

if uploaded_file is None:
    st.markdown("""
    <div style="background-color: #e3f2fd; padding: 30px; border-radius: 10px; text-align: center; margin: 30px 0;">
        <h3 style="color: #1976d2; margin-bottom: 15px;">ğŸ“‹ ì‚¬ìš© ë°©ë²•</h3>
        <p style="color: #424242; font-size: 16px; line-height: 1.6;">
            1. ì •ë¹„ ë°ì´í„°ê°€ í¬í•¨ëœ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”<br>
            2. HEROê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤<br>
            3. ì±—ë´‡ì„ í†µí•´ ì •ë¹„ ë¬¸ì œ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ì„¸ìš”
        </p>
    </div>
    """, unsafe_allow_html=True)
    st.stop()

# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
    df = pd.read_excel(uploaded_file)
    if 'ì •ë¹„ì¼ì' in df.columns:
        df['ì •ë¹„ì¼ì'] = pd.to_datetime(df['ì •ë¹„ì¼ì'], errors='coerce')
    
    df = df.dropna(subset=['ì •ë¹„ë…¸íŠ¸'])
    
    # ì„±ê³µ ë©”íŠ¸ë¦­ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h2 style="color: #1976d2; margin: 0;">{len(df):,}</h2>
            <p style="margin: 5px 0 0 0; color: #666;">ì´ ì •ë¹„ ê¸°ë¡</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        unique_equip = df['ëª¨ë¸'].nunique() if 'ëª¨ë¸' in df.columns else 0
        st.markdown(f"""
        <div class="metric-card">
            <h2 style="color: #388e3c; margin: 0;">{unique_equip}</h2>
            <p style="margin: 5px 0 0 0; color: #666;">ì¥ë¹„ ì¢…ë¥˜</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        date_range = "N/A"
        if 'ì •ë¹„ì¼ì' in df.columns and not df['ì •ë¹„ì¼ì'].isna().all():
            start_date = df['ì •ë¹„ì¼ì'].min().strftime('%Y-%m')
            end_date = df['ì •ë¹„ì¼ì'].max().strftime('%Y-%m')
            date_range = f"{start_date} ~ {end_date}"
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #f57c00; margin: 0; font-size: 14px;">{date_range}</h3>
            <p style="margin: 5px 0 0 0; color: #666;">ë°ì´í„° ê¸°ê°„</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        unique_person = df['ì •ë¹„ì'].nunique() if 'ì •ë¹„ì' in df.columns else 0
        st.markdown(f"""
        <div class="metric-card">
            <h2 style="color: #7b1fa2; margin: 0;">{unique_person}</h2>
            <p style="margin: 5px 0 0 0; color: #666;">ì •ë¹„ ë‹´ë‹¹ì</p>
        </div>
        """, unsafe_allow_html=True)

# ë¬¸ì œ ì›ì¸ ë¶„ì„
problem_keywords = [
    "wafer not", "plasma ignition failure", "pumpdown ì‹œê°„ ì§€ì—°",
    "mass flow controller ì´ìƒ", "etch residue over spec",
    "temperature drift", "slot valve ë™ì‘ ë¶ˆëŸ‰",
    "chamber pressure fluctuation", "he flow deviation", "RF auto match ë¶ˆëŸ‰"
]

alias_map = {
    "wafer not ê°ì§€ë¨": "wafer not",
    "wafer not ë°œìƒ": "wafer not",
    "rf auto match fail": "RF auto match ë¶ˆëŸ‰",
    "slot valve ë¶ˆëŸ‰": "slot valve ë™ì‘ ë¶ˆëŸ‰",
    "he flow dev": "he flow deviation",
}

def normalize_note(note: str) -> str:
    note = str(note).lower()
    note = re.sub(r'\s+', ' ', note)
    return note

def extract_cause(note: str):
    note_low = normalize_note(note)
    for alias, norm in alias_map.items():
        if alias in note_low:
            return norm
    for keyword in problem_keywords:
        if keyword.lower() in note_low:
            return keyword
    return "ê¸°íƒ€"

df['ë¬¸ì œì›ì¸'] = df['ì •ë¹„ë…¸íŠ¸'].apply(extract_cause)

# ì„±ê³µë¥  ê³„ì‚°
all_texts = [str(note).strip() for note in df['ì •ë¹„ë…¸íŠ¸']]
cause_pattern = re.compile(r'LOT ì§„í–‰ ì¤‘ (.+) ë°œìƒ')
first_action_pattern = re.compile(r'1ì°¨ ì¡°ì¹˜: (.+) â†’ ì—¬ì „íˆ ì´ìƒ ë°œìƒ')
second_action_pattern = re.compile(r'ì •ë¹„ ì‹œì‘\. (.+) ì§„í–‰')
third_action_pattern = re.compile(r'ì¶”ê°€ ì¡°ì¹˜: (.+)')

cause_aliases = {
    "wafer not ë°œìƒ": "wafer not",
    "wafer not ê°ì§€ë¨": "wafer not",
    "wafer not ë°œìƒ í™•ì¸": "wafer not",
}

def normalize_cause(cause):
    for alias, norm in cause_aliases.items():
        if alias in cause:
            return norm
    return cause

cause_action_counts = defaultdict(lambda: defaultdict(Counter))
note_map = defaultdict(list)

for idx, note in enumerate(all_texts):
    lines = [line.strip() for line in note.split('\n') if line.strip()]
    cause = None
    for line in lines:
        cause_match = cause_pattern.search(line)
        if cause_match:
            cause = normalize_cause(cause_match.group(1).strip())
            continue
        if cause is None:
            continue

        action = None
        m1 = first_action_pattern.search(line)
        m2 = second_action_pattern.search(line)
        m3 = third_action_pattern.search(line)

        if m1:
            action = m1.group(1).strip()
            cause_action_counts[cause][action]['first'] += 1
        elif m2:
            action = m2.group(1).strip()
            cause_action_counts[cause][action]['second'] += 1
        elif m3:
            action = m3.group(1).strip()
            cause_action_counts[cause][action]['third'] += 1

        if action:
            note_map[(cause, action)].append(note)

rows = []
for cause, actions in cause_action_counts.items():
    for action, counts in actions.items():
        first_count = counts['first']
        second_count = counts['second']
        third_count = counts['third']
        total = first_count + second_count + third_count
        success = second_count + third_count
        success_rate = round(success / total * 100, 2) if total > 0 else 0

        rows.append({
            "ëŒ€í‘œì›ì¸": cause,
            "ì¡°ì¹˜": action,
            "ì´íšŸìˆ˜": total,
            "ì‹¤íŒ¨íšŸìˆ˜": first_count,
            "ì„±ê³µíšŸìˆ˜": success,
            "ì„±ê³µë¥ (%)": success_rate,
            "ì •ë¹„ë…¸íŠ¸": note_map[(cause, action)][0] if note_map[(cause, action)] else ""
        })

df_success = pd.DataFrame(rows)

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
documents = [
    Document(page_content=str(row['ì •ë¹„ë…¸íŠ¸']), metadata={'row': idx})
    for idx, row in df.iterrows()
]

splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(documents)

INDEX_PATH = "faiss_index.index"

from langchain.docstore import InMemoryDocstore

def load_or_create_vectordb(documents, embedding_model):
    if os.path.exists(INDEX_PATH):
        try:
            index = faiss.read_index(INDEX_PATH)
            index_to_docstore_id = {i: str(i) for i in range(len(documents))}
            docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})
            vectordb = FAISS(
                embedding_function=embedding_model.embed_query,
                index=index,
                docstore=docstore,
                index_to_docstore_id=index_to_docstore_id
            )
        except:
            vectordb = FAISS.from_documents(documents, embedding_model)
            faiss.write_index(vectordb.index, INDEX_PATH)
    else:
        vectordb = FAISS.from_documents(documents, embedding_model)
        faiss.write_index(vectordb.index, INDEX_PATH)
    return vectordb

if "embedding_model" not in st.session_state or "vectordb" not in st.session_state:
    with st.spinner("ğŸ¤– AI ëª¨ë¸ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")
        vectordb = load_or_create_vectordb(split_docs, embedding_model)
        st.session_state["embedding_model"] = embedding_model
        st.session_state["vectordb"] = vectordb
else:
    embedding_model = st.session_state["embedding_model"]
    vectordb = st.session_state["vectordb"]

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(search_kwargs={'k': 20}),
    return_source_documents=True
)

# ----------------------------
# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
# ----------------------------
tab1, tab2 = st.tabs(["ğŸ¤– AI ì •ë¹„ ìƒë‹´", "ğŸ“Š ì •ë¹„ ë°ì´í„° ë¶„ì„"])

# ----------------------------
# Tab1: AI ì •ë¹„ ìƒë‹´
# ----------------------------
with tab1:
    st.markdown("### ğŸ¤– HERO AI ìƒë‹´ì‚¬")
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    chat_container = st.container()
    
    with chat_container:
        # ì´ˆê¸° ì¸ì‚¬ë§
        if not st.session_state.messages:
            st.markdown("""
            <div class="bot-message">
                <strong>ğŸ¤– HERO</strong><br>
                ì•ˆë…•í•˜ì„¸ìš”! ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì „ë¬¸ AI HEROì…ë‹ˆë‹¤ ğŸ‘‹<br><br>
                ì •ë¹„ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì‹œë©´, ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ë¶„ì„í•´ì„œ ìµœì ì˜ í•´ê²°ì±…ì„ ì œì•ˆí•´ë“œë ¤ìš”!<br><br>
                ğŸ’¡ <strong>ì˜ˆì‹œ:</strong> wafer not | plasma ignition failure | slot valve ë™ì‘ ë¶ˆëŸ‰
            </div>
            """, unsafe_allow_html=True)
        
        # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(f'<div class="user-message">ğŸ‘¤ {message["content"]}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="bot-message">ğŸ¤– {message["content"]}</div>', unsafe_allow_html=True)
    
    # ì‚¬ìš©ì ì…ë ¥
    col1, col2 = st.columns([4, 1])
    
    with col1:
        user_input = st.text_input(
            "ì •ë¹„ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
            key="user_input",
            placeholder="ì˜ˆ: slot valve ë™ì‘ì´ ì•ˆë¼ìš”...",
            label_visibility="collapsed"
        )
    
    with col2:
        send_button = st.button("ğŸ“¤ ì „ì†¡", use_container_width=True)
    
    if send_button and user_input.strip():
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.spinner("ğŸ” ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # RAG ê²€ìƒ‰
            output = qa_chain({"query": user_input})
            docs = output['source_documents']
            
            recommended = []
            seen_pairs = set()
            
            for doc in docs:
                note = doc.page_content.strip()
                for _, row in df_success.iterrows():
                    if row["ì¡°ì¹˜"] in note:
                        key = (row["ì¡°ì¹˜"], note)
                        if key in seen_pairs:
                            continue
                        seen_pairs.add(key)
                        
                        matched_row = df[df['ì •ë¹„ë…¸íŠ¸'].astype(str).str.strip() == note]
                        equip_id = matched_row['ì¥ë¹„ID'].iloc[0] if 'ì¥ë¹„ID' in df.columns and not matched_row.empty else 'N/A'
                        model = matched_row['ëª¨ë¸'].iloc[0] if 'ëª¨ë¸' in df.columns and not matched_row.empty else 'N/A'
                        
                        recommended.append({
                            "ì¡°ì¹˜": row["ì¡°ì¹˜"],
                            "ì„±ê³µë¥ ": row["ì„±ê³µë¥ (%)"],
                            "ì •ë¹„ë…¸íŠ¸": note,
                            "ì¥ë¹„ID": equip_id,
                            "ëª¨ë¸": model
                        })
            
            if not recommended:
                bot_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë¹„ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
            else:
                # Top3 ì„ ì •
                def is_final_action(note: str):
                    return ("ì¶”ê°€ ì¡°ì¹˜" in note) or ("ì •ìƒ í™•ì¸" in note)
                
                final_candidates = [r for r in recommended if is_final_action(r["ì •ë¹„ë…¸íŠ¸"])]
                candidates_sorted = sorted(final_candidates, key=lambda x: x["ì„±ê³µë¥ "], reverse=True)
                
                top3 = []
                used_actions = set()
                used_notes = set()
                for r in candidates_sorted:
                    note_key = r["ì •ë¹„ë…¸íŠ¸"]
                    if r["ì¡°ì¹˜"] not in used_actions and note_key not in used_notes:
                        top3.append(r)
                        used_actions.add(r["ì¡°ì¹˜"])
                        used_notes.add(r["ì •ë¹„ë…¸íŠ¸"])
                    if len(top3) == 3:
                        break
                
                if len(top3) < 3:
                    for r in sorted(recommended, key=lambda x: x["ì„±ê³µë¥ "], reverse=True):
                        if r["ì¡°ì¹˜"] not in used_actions and r["ì •ë¹„ë…¸íŠ¸"] not in used_notes:
                            top3.append(r)
                            used_actions.add(r["ì¡°ì¹˜"])
                            used_notes.add(r["ì •ë¹„ë…¸íŠ¸"])
                        if len(top3) == 3:
                            break
                
                # ì‘ë‹µ ìƒì„±
                top3_desc = "\n".join([f"{i+1}. {r['ì¡°ì¹˜']} (ì„±ê³µë¥  {r['ì„±ê³µë¥ ']}%)"
                                     for i, r in enumerate(top3)])
                
                prompt = f"""
ë‹¤ìŒì€ ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì´ìŠˆì— ëŒ€í•œ Top3 ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜ì…ë‹ˆë‹¤.
ê° ì¡°ì¹˜ì˜ ì˜ë¯¸ì™€ íŠ¹ì§•ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

{top3_desc}
                """
                explanation = llm.predict(prompt)
                
                bot_response = f"""
<strong>âœ… ì¶”ì²œ í•´ê²°ì±… Top 3</strong><br><br>
{top3_desc.replace(chr(10), '<br>')}<br><br>
<strong>ğŸ’¡ ìƒì„¸ ì„¤ëª…:</strong><br>
{explanation}
                """
        
        # ë´‡ ì‘ë‹µ ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

# ----------------------------
# Tab2: ì •ë¹„ ë°ì´í„° ë¶„ì„
# ----------------------------
with tab2:
    st.markdown("### ğŸ“Š ì •ë¹„ ë°ì´í„° ë¶„ì„")
    
    analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs(["ğŸ† í•µì‹¬ ì§€í‘œ", "ğŸ“ˆ ì „ì²´ í˜„í™©", "ğŸ”§ ì¥ë¹„ë³„ ë¶„ì„"])
    
    with analysis_tab1:
        st.markdown("#### ğŸ† í•µì‹¬ ì§€í‘œ TOP 5")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ğŸ”§ ê³ ì¥ ë¹ˆë°œ ì¥ë¹„")
            top5_equip = df['ëª¨ë¸'].value_counts().head(5)
            
            fig1 = px.bar(
                x=top5_equip.values,
                y=top5_equip.index,
                orientation='h',
                text=[f"{v}ê±´" for v in top5_equip.values],
                color=top5_equip.values,
                color_continuous_scale='Blues',
                height=400
            )
            fig1.update_traces(textposition='outside')
            fig1.update_layout(showlegend=False, margin=dict(l=0, r=0, t=0, b=0))
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            st.markdown("##### âš ï¸ ì£¼ìš” ë¬¸ì œ ì›ì¸")
            top5_cause = df['ë¬¸ì œì›ì¸'].value_counts().head(5)
            
            fig2 = px.bar(
                x=top5_cause.values,
                y=top5_cause.index,
                orientation='h',
                text=[f"{v}ê±´" for v in top5_cause.values],
                color=top5_cause.values,
                color_continuous_scale='Reds',
                height=400
            )
            fig2.update_traces(textposition='outside')
            fig2.update_layout(showlegend=False, margin=dict(l=0, r=0, t=0, b=0))
            st.plotly_chart(fig2, use_container_width=True)
        
        # AI ì¸ì‚¬ì´íŠ¸
        st.markdown("#### ğŸ§  AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
        
        with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            prompt_insight = f"""
ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ì— ëŒ€í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

ê³ ì¥ ë¹ˆë°œ ì¥ë¹„ TOP5: {', '.join(top5_equip.index)}
ì£¼ìš” ë¬¸ì œ ì›ì¸ TOP5: {', '.join(top5_cause.index)}

ì˜ˆë°© ì •ë¹„ì™€ ìš´ì˜ íš¨ìœ¨ì„± ê´€ì ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
            """
            
            insight = llm.predict(prompt_insight)
            
            st.markdown(f"""
            <div class="success-card">
                <h4 style="margin-top: 0;">ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸</h4>
                <p style="margin-bottom: 0; line-height: 1.6;">{insight}</p>
            </div>
            """, unsafe_allow_html=True)
    
    with analysis_tab2:
        st.markdown("#### ğŸ“ˆ ì „ì²´ í˜„í™© ë¶„ì„")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ğŸ­ ì¥ë¹„ë³„ ê³ ì¥ ë¶„í¬")
            total_equip = df['ëª¨ë¸'].value_counts()
            
            fig_pie1 = px.pie(
                names=total_equip.index.tolist(),
                values=total_equip.values,
                hole=0.4,
                height=400
            )
            fig_pie1.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_pie1, use_container_width=True)
        
        with col2:
            st.markdown("##### ğŸ” ë¬¸ì œ ì›ì¸ ë¶„í¬")
            total_cause = df['ë¬¸ì œì›ì¸'].value_counts()
            
            fig_pie2 = px.pie(
                names=total_cause.index.tolist(),
                values=total_cause.values,
                hole=0.4,
                height=400
            )
            fig_pie2.update_traces(textinfo='percent+label')
            st.plotly_chart(fig_pie2, use_container_width=True)
        
        # ì „ì²´ í˜„í™© AI ì¸ì‚¬ì´íŠ¸
        st.markdown("#### ğŸ§  ì „ì²´ í˜„í™© AI ë¶„ì„")
        
        with st.spinner("ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            prompt_total = f"""
ë‹¤ìŒì€ ì „ì²´ ì¥ë¹„ ê³ ì¥ ë° ë¬¸ì œ ì›ì¸ ë¶„í¬ ë°ì´í„°ì…ë‹ˆë‹¤:

ì¥ë¹„ë³„ ë¶„í¬: {dict(total_equip.head(3))}
ë¬¸ì œ ì›ì¸ë³„ ë¶„í¬: {dict(total_cause.head(3))}

ì „ì²´ì ì¸ íŒ¨í„´ê³¼ ìš´ì˜ ê°œì„  ë°©í–¥ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
            """
            
            total_insight = llm.predict(prompt_total)
            
            st.markdown(f"""
            <div class="success-card">
                <h4 style="margin-top: 0;">ğŸ“Š ì „ì²´ í˜„í™© ë¶„ì„</h4>
                <p style="margin-bottom: 0; line-height: 1.6;">{total_insight}</p>
            </div>
            """, unsafe_allow_html=True)
    
    with analysis_tab3:
        st.markdown("#### ğŸ”§ ì¥ë¹„ë³„ ìƒì„¸ ë¶„ì„")
        
        # ì¥ë¹„ ì„ íƒ
        equip_list = df['ëª¨ë¸'].dropna().unique().tolist()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            selected_equip = st.selectbox(
                "ë¶„ì„í•  ì¥ë¹„ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                ["ì „ì²´ ì¥ë¹„"] + equip_list,
                help="íŠ¹ì • ì¥ë¹„ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì¥ë¹„ì˜ ìƒì„¸ ë¶„ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
        
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <h3 style="color: #1976d2; margin: 0;">{len(equip_list)}</h3>
                <p style="margin: 5px 0 0 0; color: #666;">ì´ ì¥ë¹„ ì¢…ë¥˜</p>
            </div>
            """, unsafe_allow_html=True)
        
        if selected_equip != "ì „ì²´ ì¥ë¹„":
            # ì„ íƒëœ ì¥ë¹„ ë°ì´í„° í•„í„°ë§
            df_filtered = df[df['ëª¨ë¸'] == selected_equip]
            
            if df_filtered.empty:
                st.warning(f"âš ï¸ ì„ íƒí•œ ì¥ë¹„({selected_equip})ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¥ë¹„ ì •ë³´ ìš”ì•½
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h2 style="color: #d32f2f; margin: 0;">{len(df_filtered)}</h2>
                        <p style="margin: 5px 0 0 0; color: #666;">ì´ ê³ ì¥ ê±´ìˆ˜</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    unique_causes = df_filtered['ë¬¸ì œì›ì¸'].nunique()
                    st.markdown(f"""
                    <div class="metric-card">
                        <h2 style="color: #f57c00; margin: 0;">{unique_causes}</h2>
                        <p style="margin: 5px 0 0 0; color: #666;">ë¬¸ì œ ì›ì¸ ì¢…ë¥˜</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    if 'ì •ë¹„ì' in df_filtered.columns:
                        unique_maintainers = df_filtered['ì •ë¹„ì'].nunique()
                    else:
                        unique_maintainers = 0
                    st.markdown(f"""
                    <div class="metric-card">
                        <h2 style="color: #388e3c; margin: 0;">{unique_maintainers}</h2>
                        <p style="margin: 5px 0 0 0; color: #666;">ë‹´ë‹¹ ì •ë¹„ì</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                # ì¥ë¹„ë³„ ë¬¸ì œ ì›ì¸ ë¶„ì„
                st.markdown(f"##### ğŸ” {selected_equip} ë¬¸ì œ ì›ì¸ ë¶„ì„")
                
                cause_counts = df_filtered['ë¬¸ì œì›ì¸'].value_counts()
                
                # ë¬¸ì œ ì›ì¸ ì°¨íŠ¸
                fig_equip = px.bar(
                    x=cause_counts.values,
                    y=cause_counts.index,
                    orientation='h',
                    text=[f"{v}ê±´" for v in cause_counts.values],
                    color=cause_counts.values,
                    color_continuous_scale='Viridis',
                    height=400
                )
                fig_equip.update_traces(textposition='outside')
                fig_equip.update_layout(
                    title=f"{selected_equip} ë¬¸ì œ ì›ì¸ë³„ ë°œìƒ ë¹ˆë„",
                    showlegend=False,
                    margin=dict(l=0, r=0, t=40, b=0)
                )
                st.plotly_chart(fig_equip, use_container_width=True)
                
                # ì„ íƒëœ ì¥ë¹„ì˜ ì¶”ì²œ ì¡°ì¹˜
                if len(cause_counts) > 0:
                    st.markdown("##### ğŸ› ï¸ ì¶”ì²œ ì •ë¹„ ì¡°ì¹˜")
                    
                    top_cause = cause_counts.index[0]
                    
                    # í•´ë‹¹ ì›ì¸ì— ëŒ€í•œ ì„±ê³µë¥  ë†’ì€ ì¡°ì¹˜ ì°¾ê¸°
                    cause_actions = df_success[df_success['ëŒ€í‘œì›ì¸'] == top_cause]
                    
                    if not cause_actions.empty:
                        top_actions = cause_actions.nlargest(3, 'ì„±ê³µë¥ (%)')
                        
                        st.markdown(f"**'{top_cause}' ë¬¸ì œì— ëŒ€í•œ ì¶”ì²œ ì¡°ì¹˜ TOP 3:**")
                        
                        for idx, (_, action_row) in enumerate(top_actions.iterrows(), 1):
                            success_rate = action_row['ì„±ê³µë¥ (%)']
                            action_name = action_row['ì¡°ì¹˜']
                            
                            # ì„±ê³µë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                            if success_rate >= 80:
                                color = "#4caf50"  # ì´ˆë¡
                                icon = "ğŸŸ¢"
                            elif success_rate >= 60:
                                color = "#ff9800"  # ì£¼í™©
                                icon = "ğŸŸ¡"
                            else:
                                color = "#f44336"  # ë¹¨ê°•
                                icon = "ğŸ”´"
                            
                            st.markdown(f"""
                            <div style="background-color: white; border-left: 4px solid {color}; 
                                        padding: 15px; margin: 10px 0; border-radius: 5px; 
                                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                <strong>{icon} {idx}. {action_name}</strong><br>
                                <span style="color: {color}; font-weight: bold;">ì„±ê³µë¥ : {success_rate}%</span>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("í•´ë‹¹ ë¬¸ì œ ì›ì¸ì— ëŒ€í•œ ì¡°ì¹˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                
                # ì¥ë¹„ë³„ AI ì¸ì‚¬ì´íŠ¸
                st.markdown("#### ğŸ¤– ì¥ë¹„ë³„ AI ë¶„ì„")
                
                with st.spinner(f"{selected_equip} ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    prompt_equip = f"""
ë‹¤ìŒì€ {selected_equip} ì¥ë¹„ì˜ ì •ë¹„ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

- ì´ ê³ ì¥ ê±´ìˆ˜: {len(df_filtered)}ê±´
- ì£¼ìš” ë¬¸ì œ ì›ì¸: {', '.join(cause_counts.head(3).index)}
- ë¬¸ì œ ë°œìƒ ë¹ˆë„: {dict(cause_counts.head(3))}

ì´ ì¥ë¹„ì˜ íŠ¹ì„±ê³¼ ë¬¸ì œ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆë°© ì •ë¹„ ë°©ì•ˆì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
                    """
                    
                    equip_insight = llm.predict(prompt_equip)
                    
                    st.markdown(f"""
                    <div class="success-card">
                        <h4 style="margin-top: 0;">ğŸ”§ {selected_equip} ë§ì¶¤ ë¶„ì„</h4>
                        <p style="margin-bottom: 0; line-height: 1.6;">{equip_insight}</p>
                    </div>
                    """, unsafe_allow_html=True)
        
        else:
            # ì „ì²´ ì¥ë¹„ ì„ íƒ ì‹œ
            st.markdown("##### ğŸ“‹ ì „ì²´ ì¥ë¹„ í˜„í™©")
            
            # ì¥ë¹„ë³„ ê³ ì¥ ê±´ìˆ˜ í…Œì´ë¸”
            equip_summary = df.groupby('ëª¨ë¸').agg({
                'ì •ë¹„ë…¸íŠ¸': 'count',
                'ë¬¸ì œì›ì¸': lambda x: x.value_counts().index[0] if len(x) > 0 else 'N/A'
            }).rename(columns={
                'ì •ë¹„ë…¸íŠ¸': 'ê³ ì¥ê±´ìˆ˜',
                'ë¬¸ì œì›ì¸': 'ì£¼ìš”ë¬¸ì œì›ì¸'
            }).sort_values('ê³ ì¥ê±´ìˆ˜', ascending=False)
            
            st.dataframe(
                equip_summary,
                use_container_width=True,
                height=400
            )
            
            st.info("ğŸ‘† íŠ¹ì • ì¥ë¹„ë¥¼ ì„ íƒí•˜ì‹œë©´ ë” ìƒì„¸í•œ ë¶„ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>ğŸš€ <strong>HERO</strong> - Hynix Equipment Response Operator</p>
    <p>AI ê¸°ë°˜ ë°˜ë„ì²´ ì¥ë¹„ ì •ë¹„ ì†”ë£¨ì…˜ | Powered by OpenAI GPT-4</p>
</div>
""", unsafe_allow_html=True)
